## 机器规划
### 机器配置
> 总共6台,机器配置为2个20核，256G内存，Radid5 12 x 188G SSD 2*10G网口
### 部署原则
> 采用 3 + 3 的模式，将所有支撑组件分成两组，每组在3台机器中部署
### 装机说明
> 系统：Tlinux2.2，需要调整根分区，不能让根分区只有10G
> 修改root密码
> 手动安装dcos_agent, 配置barad告警（磁盘告警需要涵盖root data data1 data2分区）
> 安装前执行ntpdate，并将时区修改至东八区
> 六台支撑组件机器都需要修改/etc/resolv.conf文件，将gaiastack计算节点的node1和node2的ip设置为dnsserver
### 机器分配
> <font color=red>注意：HDFS ES KAFKA CDB四个组件对磁盘容量需求较大，因此需要平均分配到两组机器中</font>
#### 分组 1 （机器 1/2/3）
- hdfs
> 修改hdfs-site.xml中数据目录为/data2
- zk3.4.6
> 修改zoo.cfg中数据目录为/data,连接数配置为600
- CKV(Redis)
> ckv + oss 部署在机器3，默认数据目录为/data/service
- ES
> 默认数据目录为 /data1
- cdb非存储组件
> 部署在机器 1 和 2 上
> ansible 配置的组件，除了zk需要配置3台，其它都放在机器 1 和机器 2 上

#### 分组 2 （机器4/5/6）
- CDB存储组件 + PGW两台 + ZK3台
> 2 台 PGW，创建集群时制定的gw_ip_list:机器 4 5
> 3 台PCDB实例机，默认数据目录为/data1，binlog 目录为 /data
- Kafka0.9
> 修改server.properties修改数据目录为/data2/kafka-logs
- rabbitmq
> 部署在机器4/5 ，默认安装路径为/usr/local/services，数据目录为/data/rabbitmq
- memcache
> 部署在机器6，将安装包cp 到/data/目录，执行安装

# 部署
## CDB(旧版)
> 组成：
  > OSS master(对应安装参数 -m oss_master_ip) slaver(对应安装参数：-a oss_slaver_ip)
  > zookeeper(对应安装参数 -i zk_iplist，-n zk_node_num, -t zk_deploy_type:local/remote)
  > 拨测系统：pingmar pingsvr(对应参数 -p ping_iplist, -s 拨测 server 的 set 号)
  > 监控项采集： monitor_collector(对应安装参数 -c monitor_collect_ips,为空时采用master,slaver)
  > 备份系统：
    > backup_scheduler(对应安装参数 -b backup_schedular_ip,为空时采用oss_web ip)
    > backupd(对应安装参数 -k backupd_ip, 为空时采用backup_scheduler_ip)
  > 高可用系统：ha_scheduler(对应安装参数 -h ha_schedular_ip, 为空时采用oss_web ip)
  > 网关：cdb_gateway(对应安装参数 -g cdb_gateway_ip，为空时采用oss_web ip)
  > 最小化部署三台机器即可
  > binlog 需要/data目录  数据 需要/data1目录
  > 其它参数 -o:集群名称，-r：地域名称 -y:audit_report_host(审计上报ip:port)
1. 配置时钟同步
2. 解压缩物料包 
  > 将 cdb_auto_deploy.v0208.a347b9e.tar.gz 发送至 oss master/slaver
  > 所有主机安装 cdb_worker(3883端口)
3. 安装 OSS
> cd /data/cdb_auto_deploy/install_sh
> `./one_key_install_oss_master.sh -n3 -t'remote' -i'172.16.14.151 172.16.14.152 172.16.14.157' -o128 -p'172.16.14.148 172.16.14.149' -r'pcdb_test' -a'172.16.14.149' -y'172.16.14.148:8888' ` master
> `./one_key_install_oss_master.sh -n3 -t'remote' -i'172.16.14.151 172.16.14.152 172.16.14.157' -o128 -p'172.16.14.148 172.16.14.149' -r'pcdb_test' -a'172.16.14.152' -y'172.16.14.152:8888' `
  > 14步
  > init_install_env mysql_client zk mysql&apache dbmaster monitor_collect ha_scheduler ping cdb_gateway backup_scheduler backup_mounter backupd cdb_oss check_install
>  `./one_key_install_oss_slave.sh -n3 -t'remote' -i'172.16.14.151 172.16.14.152 172.16.14.157' -o128 -p'172.16.14.151 172.16.14.152' -r'pcdb_test' -m'172.16.14.148' -y'172.16.14.148:8888' ` slaver
> `./one_key_install_oss_slave.sh -n3 -t'remote' -i'172.16.14.151 172.16.14.152 172.16.14.157' -o128 -p'172.16.14.151 172.16.14.152' -r'pcdb_test' -m'172.16.14.151' -y'172.16.14.151:8888' `
  > 11步
  > init_install_env get_zk_hosts mysql&apache dbmaster ha_scheduler cdb_gateway back_scheduler backup_mounter backupd cdb_oss zknode_detector
> `cd /data/cdb_auto_deploy/install_sh &&  ./one_key_uninstall.sh  -p '172.16.14.148 172.16.14.149'  -i '172.16.14.151 172.16.14.152 172.16.14.157'`清理环境

4. 使用OSS接口
  - 创建集群
```
curl -d 'data={
    "gw_ip_list":[
        "172.16.14.151",
        "172.16.14.152"],
    "cluster_name": "tce_cluster",
    "base_port":22001,
    "backup":{
        "name":"chongqing",
        "region":"chongqing",
        "storage":"hdfs",
        "cmd":{
            "namenode":"172.16.14.151:9000"
        }
    },
    "operator":"tceadmin"
        }' http://172.16.14.151:8080/cdb2/fun_logic/cgi-bin/public_api_20/pcdb_create_cluster.cgi
  ``` 
  - 查询任务状态
  ```
  curl -d 'data={
    "job_id":"90",
    "operator": "tceadmin"
    }' "http://172.16.14.151:8080/cdb2/fun_logic/cgi-bin/public_api_20/pcdb_query_task.cgi"
  ```
 - 查询集群状态
 ```
 curl -d 'data={
   "cluster_id":2, 
   "cur_page":0, 
   "per_page": 20, 
   "detail": 0, 
   "operator": "liuronghu"
   }' "http://172.16.14.151:8080/cdb2/fun_logic/cgi-bin/public_api_20/pcdb_query_cluster.cgi"
 ```
  - 插入机型元数据

  - 上架机器
```
curl -d 'data={
  "cluster_id":2,
   "operator":"tceadmin", 
   "dev_list":[
     {"ip":"172.16.14.157",
     "dev_class":"TS90",
     "rack_id":"0",
     "rack":"WH50204AC01",
     "switch_ip":"",
     "parent_idc":"",
     "idc_id":"0",
     "idc":"nanhu",
     "szone_id":"1",
     "zone_id": "2",
     "zone": "wuhanyiqu",
     "region_id": "3",
     "region": "wuhan",
     "cpu": 10,
     "mem": 163840,
     "disk": 20000,
     "data_dir":"/data1",
     "szone": "chongqing"}
     ]
     }' "http://172.16.14.151:8080/cdb2/fun_logic/cgi-bin/public_api_20/pcdb_install_dev.cgi"
```
- 查询机器
```
curl -d 'data={
 "cluster_id":2, 
 "operator":"tceadmin", 
 "cur_page":0, 
 "per_page":20, 
 "ip_list":["172.16.14.151",
 "172.16.14.152",
 "172.16.14.157"]}' "http://172.16.14.151:8080/cdb2/fun_logic/cgi-bin/public_api_20/pcdb_query_dev.cgi"
```
 - 下架机器
```
curl -d 'data={"cluster_id":2,
  "ip_list":[
    "172.16.14.152",
    "172.16.14.157"],
  "operator":"liuronghu"}' "http://172.16.14.151:8080/cdb2/fun_logic/cgi-bin/public_api_20/pcdb_remove_dev.cgi"
```
  - 创建实例
```
curl -d 'data={
  "cluster_id":2,
  "app_domain":"app01",
  "set_name":"set01",
  "slave_num":2,
  "mem":16000,
  "disk":200,
  "cpu":2,
  "dev_class":"TS90",
  "mysql_version":"5.6",
  "sync_way":"sync",
  "disaster_type":"rack", 
  "operator": "tceadmin"
  }' "http://172.16.14.151:8080/cdb2/fun_logic/cgi-bin/public_api_20/pcdb_apply_set.cgi"
```
  - 创建用户（读写、只读）